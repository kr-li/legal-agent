# english_contract_analyzer.py
import os
import tempfile
from pathlib import Path
from typing import List, Dict, Any
import gradio as gr
from modelscope import AutoModelForCausalLM, AutoTokenizer
from transformers import AutoTokenizer,AutoModelForCausalLM
from modelscope import snapshot_download
import numpy as np
from transformers.models.qwen2_5_omni.configuration_qwen2_5_omni import Qwen2_5OmniConfig


class EnglishContractAnalyzer:
    def __init__(self, model_name="Qwen/Qwen2.5-Omni-7B"):
        self.model_name = model_name
        self.model, self.tokenizer = self.load_model()
        self.supported_formats = ['.pdf', '.docx', '.doc', '.txt']

    def load_model(self):
        """åŠ è½½ModelScopeæ¨¡å‹"""
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_name}")

        try:
            # ä¸‹è½½æ¨¡å‹ï¼ˆå¦‚æœå°šæœªä¸‹è½½ï¼‰
            model_dir = snapshot_download(self.model_name)

            tokenizer = AutoTokenizer.from_pretrained(
                model_dir,
                trust_remote_code=True
            )

            model = AutoModelForCausalLM.from_pretrained(
                model_dir,
                device_map="auto",
                torch_dtype="auto",
                trust_remote_code=True
            )

            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            return model, tokenizer

        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """ä»PDFæå–æ–‡æœ¬"""
        try:
            import pdfplumber
            text = ""
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
            return text
        except Exception as e:
            print(f"PDFæå–å¤±è´¥: {e}")
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨pdfminer
            try:
                from pdfminer.high_level import extract_text as pdfminer_extract
                return pdfminer_extract(pdf_path)
            except:
                return f"PDFæ–‡æœ¬æå–å¤±è´¥: {e}"

    def extract_text_from_docx(self, docx_path: str) -> str:
        """ä»Wordæ–‡æ¡£æå–æ–‡æœ¬"""
        try:
            import docx
            doc = docx.Document(docx_path)
            text = "\n".join([paragraph.text for paragraph in doc.paragraphs])
            return text
        except Exception as e:
            print(f"DOCXæå–å¤±è´¥: {e}")
            return f"Wordæ–‡æ¡£æå–å¤±è´¥: {e}"

    def extract_text_from_file(self, file_path: str) -> str:
        """æ ¹æ®æ–‡ä»¶ç±»å‹æå–æ–‡æœ¬"""
        file_ext = Path(file_path).suffix.lower()

        if file_ext == '.pdf':
            return self.extract_text_from_pdf(file_path)
        elif file_ext in ['.docx', '.doc']:
            return self.extract_text_from_docx(file_path)
        elif file_ext == '.txt':
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        else:
            return f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}"

    def analyze_contract_clause(self, clause_text: str, analysis_type: str) -> str:
        """åˆ†æåˆåŒæ¡æ¬¾"""
        analysis_prompts = {
            "risk_analysis": """Analyze the following contract clause for LEGAL RISKS and provide professional assessment:

CONTRACT CLAUSE:
{clause}

Please analyze in this structure:
1. **RISK IDENTIFICATION** [List specific legal risks]
2. **SEVERITY ASSESSMENT** [High/Medium/Low for each risk]
3. **LEGAL BASIS** [Relevant laws and regulations]
4. **RECOMMENDATIONS** [Specific revision suggestions]
5. **BEST PRACTICES** [Industry standards]

Professional Analysis:""",

            "compliance_check": """Conduct COMPLIANCE REVIEW for the following contract clause:

CLAUSE:
{clause}

Check compliance with:
- General contract law principles
- Industry-specific regulations
- Jurisdictional requirements
- International standards (if applicable)

Provide: Compliance Status + Required Actions + Legal References

Compliance Analysis:""",

            "plain_explanation": """Explain this contract clause in PLAIN ENGLISH for business understanding:

CLAUSE:
{clause}

Please provide:
1. **Simple Explanation** [Clear, non-legal language]
2. **Key Obligations** [What each party must do]
3. **Practical Implications** [Real-world consequences]
4. **Important Considerations** [What to watch out for]

Plain English Explanation:""",

            "full_review": """Comprehensive LEGAL REVIEW of contract clause:

CLAUSE TEXT:
{clause}

Please provide detailed analysis covering:
1. **CLAUSE TYPE & PURPOSE**
2. **KEY TERMS & DEFINITIONS**
3. **LEGAL RISK ASSESSMENT**
4. **COMPLIANCE CHECK**
5. **NEGOTIATION POINTS**
6. **RECOMMENDED REVISIONS**
7. **ALTERNATIVE WORDING**

Comprehensive Legal Review:"""
        }

        prompt_template = analysis_prompts.get(analysis_type, analysis_prompts["risk_analysis"])
        prompt = prompt_template.format(clause=clause_text[:3000])  # é™åˆ¶é•¿åº¦

        # ç”Ÿæˆå›ç­”
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.model.device)
        outputs = self.model.generate(
            **inputs,
            max_new_tokens=1500,
            temperature=0.3,
            do_sample=True,
            pad_token_id=self.tokenizer.eos_token_id
        )

        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        return response.split("Analysis:")[-1].replace(prompt, "").strip()

    def process_uploaded_file(self, file_path: str, analysis_type: str) -> Dict[str, Any]:
        """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
        try:
            # æå–æ–‡æœ¬
            contract_text = self.extract_text_from_file(file_path)

            if "å¤±è´¥" in contract_text or "é”™è¯¯" in contract_text:
                return {
                    "success": False,
                    "error": contract_text,
                    "analysis": ""
                }

            # åˆ†æåˆåŒ
            analysis = self.analyze_contract_clause(contract_text, analysis_type)

            return {
                "success": True,
                "original_text": contract_text[:1000] + "..." if len(contract_text) > 1000 else contract_text,
                "analysis": analysis,
                "text_length": len(contract_text)
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "analysis": ""
            }


def create_advanced_interface():
    """åˆ›å»ºé«˜çº§ç•Œé¢"""
    analyzer = EnglishContractAnalyzer()

    with gr.Blocks(theme=gr.themes.Soft(), title="è‹±æ–‡åˆåŒåˆ†æç³»ç»Ÿ") as demo:
        gr.Markdown("# ğŸ‡ºğŸ‡¸ è‹±æ–‡åˆåŒæ™ºèƒ½åˆ†æç³»ç»Ÿ")
        gr.Markdown("åŸºäºModelScopeå¤§æ¨¡å‹çš„è‹±æ–‡æ³•å¾‹åˆåŒåˆ†æå·¥å…·")

        with gr.Tabs() as tabs:
            with gr.TabItem("ğŸ“ æ–‡ä»¶åˆ†æ"):
                with gr.Row():
                    with gr.Column(scale=1):
                        file_input = gr.File(
                            label="ä¸Šä¼ åˆåŒæ–‡ä»¶",
                            file_types=[".pdf", ".docx", ".doc", ".txt"],
                            type="filepath"
                        )
                        analysis_type = gr.Radio(
                            choices=["risk_analysis", "compliance_check", "plain_explanation", "full_review"],
                            label="åˆ†æç±»å‹",
                            value="risk_analysis",
                            info="é€‰æ‹©åˆ†ææ·±åº¦"
                        )
                        analyze_btn = gr.Button("å¼€å§‹åˆ†æ", variant="primary")

                    with gr.Column(scale=2):
                        original_text = gr.Textbox(
                            label="æå–çš„åˆåŒæ–‡æœ¬",
                            lines=6,
                            max_lines=10,
                            interactive=False
                        )
                        analysis_output = gr.Textbox(
                            label="åˆ†æç»“æœ",
                            lines=12,
                            interactive=False
                        )
                        file_info = gr.Textbox(
                            label="æ–‡ä»¶ä¿¡æ¯",
                            visible=False
                        )

            with gr.TabItem("ğŸ’¬ ç›´æ¥å¯¹è¯"):
                chatbot = gr.Chatbot(label="æ³•å¾‹é—®ç­”å¯¹è¯")
                msg = gr.Textbox(
                    label="è¾“å…¥è‹±æ–‡æ³•å¾‹é—®é¢˜",
                    placeholder="ä¾‹å¦‚: What are the key risks in this indemnification clause?",
                    lines=3
                )
                with gr.Row():
                    send_btn = gr.Button("å‘é€", variant="primary")
                    clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯")

        # æ–‡ä»¶åˆ†æåŠŸèƒ½
        def analyze_file(file_path, analysis_type):
            if not file_path:
                return "è¯·å…ˆä¸Šä¼ æ–‡ä»¶", "", ""

            result = analyzer.process_uploaded_file(file_path, analysis_type)

            if result["success"]:
                info = f"æ–‡æœ¬é•¿åº¦: {result['text_length']} å­—ç¬¦"
                return result["original_text"], result["analysis"], info
            else:
                return f"å¤„ç†å¤±è´¥: {result['error']}", "", ""

        analyze_btn.click(
            analyze_file,
            inputs=[file_input, analysis_type],
            outputs=[original_text, analysis_output, file_info]
        )

        # å¯¹è¯åŠŸèƒ½
        def legal_chat(message, chat_history):
            if not message.strip():
                return "", chat_history

            # æ„å»ºä¸“ä¸šæç¤ºè¯
            prompt = f"""You are a professional legal AI assistant. Please provide accurate, professional analysis for the following legal question.

Question: {message}

Please provide a comprehensive answer with legal basis and practical advice:"""

            inputs = analyzer.tokenizer(prompt, return_tensors="pt").to(analyzer.model.device)
            outputs = analyzer.model.generate(
                **inputs,
                max_new_tokens=800,
                temperature=0.3,
                do_sample=True
            )

            response = analyzer.tokenizer.decode(outputs[0], skip_special_tokens=True)
            response = response.split("advice:")[-1].strip()

            chat_history.append((message, response))
            return "", chat_history

        send_btn.click(legal_chat, [msg, chatbot], [msg, chatbot])
        msg.submit(legal_chat, [msg, chatbot], [msg, chatbot])
        clear_btn.click(lambda: [], None, chatbot)

        # ç¤ºä¾‹éƒ¨åˆ†
        with gr.Accordion("ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹", open=False):
            gr.Markdown("""
            **ç¤ºä¾‹é—®é¢˜ï¼š**
            - What are the key elements of a valid contract?
            - Explain the difference between representation and warranty
            - What risks should I look for in a service agreement?
            - How to negotiate better termination clauses?

            **æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š**
            - PDFæ–‡æ¡£ (.pdf)
            - Wordæ–‡æ¡£ (.docx, .doc)  
            - æ–‡æœ¬æ–‡ä»¶ (.txt)
            """)

    return demo


# æ‰¹é‡å¤„ç†åŠŸèƒ½
class BatchContractProcessor:
    """æ‰¹é‡åˆåŒå¤„ç†å™¨"""

    def __init__(self, analyzer):
        self.analyzer = analyzer

    def process_batch(self, input_dir: str, output_dir: str, analysis_type: str = "risk_analysis"):
        """æ‰¹é‡å¤„ç†åˆåŒæ–‡ä»¶å¤¹"""
        input_path = Path(input_dir)
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)

        results = []
        supported_files = []

        # æ”¶é›†æ”¯æŒçš„æ–‡ä»¶
        for ext in ['.pdf', '.docx', '.doc', '.txt']:
            supported_files.extend(input_path.glob(f"*{ext}"))

        for file_path in supported_files:
            print(f"å¤„ç†æ–‡ä»¶: {file_path.name}")

            try:
                result = self.analyzer.process_uploaded_file(str(file_path), analysis_type)

                if result["success"]:
                    # ä¿å­˜ç»“æœ
                    output_file = output_path / f"{file_path.stem}_analysis.txt"
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(f"File: {file_path.name}\n")
                        f.write(f"Analysis Type: {analysis_type}\n")
                        f.write("=" * 50 + "\n")
                        f.write(result["analysis"])

                    results.append({
                        "file": file_path.name,
                        "status": "success",
                        "output_file": str(output_file)
                    })
                else:
                    results.append({
                        "file": file_path.name,
                        "status": "failed",
                        "error": result["error"]
                    })

            except Exception as e:
                results.append({
                    "file": file_path.name,
                    "status": "error",
                    "error": str(e)
                })

        return results


if __name__ == "__main__":
    # å¯åŠ¨æœåŠ¡
    print("ğŸš€ å¯åŠ¨è‹±æ–‡åˆåŒåˆ†æç³»ç»Ÿ...")
    print("ğŸ“Š æ”¯æŒæ ¼å¼: PDF, Word, TXT")
    print("ğŸŒ è®¿é—®: http://localhost:7860")

    demo = create_advanced_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True
    )